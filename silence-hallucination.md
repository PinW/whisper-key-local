Hereâ€™s what I found about fasterâ€‘whisper (or Whisper-based) hallucinations when you transcribe very short or silent recordings:

---

## 1. âœ… What happens: hallucinations on silence or ultraâ€‘short audio

* Fasterâ€‘Whisper (and Whisper models generally) often **generates plausible phrases** from completely silent or ultra-short audioâ€”e.g. "okay all right", "thank you for watching"â€”even when no one speaks. This is a known behavior and quite common. ([GitHub][1])
* A major study showed that **around 40%** of nonâ€‘speech inputs (silence/noise) caused hallucinations. For 1â€‘second silent clips, about **52%** produced hallucinated text. ([arXiv][2])

---

## 2. âš™ï¸ Why it happens

* Whisper treats transcription like an LLM: even silent input it "expects" speech, and so **hallucinates based on learned patterns** from training dataâ€”often common phrases in video transcripts like â€œthank you for listeningâ€. ([Reddit][3])
* The model tends to **rely on its internal language model**, especially for very short chunks, sometimes looping repeated text across segments. ([Reddit][3])

---

## 3. ğŸ›  Solutions & mitigations

### A. Preâ€‘processing with Voice Activity Detection (VAD)

* Detect and remove silent or nonâ€‘speech audio using tools like **SileroVAD** or WebRTC VAD before sending input to Whisper. This greatly reduces hallucinations. ([arXiv][2])

### B. Model inference parameter tuning

* Setting **beam\_size = 1** minimizes hallucination rate compared to higher beam sizes. And enabling a **silence threshold** (e.g. minimum non-speech duration to skip) can further help. ([arXiv][2])
* In particular, a silence threshold of \~10â€“20â€¯s reduced hallucination detection to \~15â€“16%. ([arXiv][2])

### C. Postâ€‘processing filters (Bag of Hallucinations + deooping)

* Build a â€œbagâ€ of frequent hallucinatory phrases (like â€œthank you for watchingâ€) and filter them out. Combined with removing repeated segments ("looping"), this can significantly reduce hallucinations. ([arXiv][2])

### D. Model fineâ€‘tuning: Calmâ€‘Whisper

* A new research variant, called **Calmâ€‘Whisper** (fineâ€‘tuned on nonâ€‘speech), suppresses hallucinations by over 80% while minimally affecting real speech transcription. ([arXiv][4])

---

## 4. âœ… Recommendations for your scenario

Youâ€™re triggering hallucinations because your recordings are extremely short (<<1â€¯s) and often silent. Hereâ€™s a practical plan:

1. **Add VAD in your pipeline**: discard or skip chunks shorter than, say, 0.5â€¯s with no detected speech.
2. Use **beam\_size =â€¯1** and configure a silenceâ€‘skip threshold if supported by faster-whisper.
3. Optionally, maintain a **filter list of known hallucinated phrases**, and postâ€‘process transcripts to remove them.
4. If you need industrial-grade reliability, consider trying **Calmâ€‘Whisper** or fineâ€‘tuning same.

---

### Summary Table

| Symptom                       | Cause                              | Recommended Fix                             |
| ----------------------------- | ---------------------------------- | ------------------------------------------- |
| Hallucination on silence      | Model expects text anyway          | Use VAD to skip silent input                |
| Repeating phrases / "looping" | Chunk context issues / beam search | Set `beam_size=1`, disable context chaining |
| Frequent false phrases        | Learned from training corpus       | Filter via postâ€‘processing (BoH)            |
| Overall hallucination conc.   | Model architecture and training    | Try Calmâ€‘Whisper or select fine-tuning      |

---

## âœ… Final Thoughts

* This is a **wellâ€‘documented issue** with Whisper and fasterâ€‘whisperâ€”especially on very short or silent inputs. Hallucination rates of **\~50%** for 1-second silence are typical. ([arXiv][2], [YouTube][5], [GitHub][6])
* Confidence: \~â€¯95% that your symptoms match the known phenomenon.
* Low complexity fixes (VAD + beam\_size=1 + filtering) usually solve most cases.
* If youâ€™d like help wiring any step into your Python code, feel free to ask!

Uncertainty Map: Iâ€™m least confident about whether your version of fasterâ€‘whisper supports the exact same silenceâ€‘threshold flags. Checking documentation or your version release notes could be helpful.

[1]: https://github.com/guillaumekln/faster-whisper/issues/183?utm_source=chatgpt.com "Low performance on silent audios Â· Issue #183"
[2]: https://arxiv.org/html/2501.11378v1?utm_source=chatgpt.com "Investigation of Whisper ASR Hallucinations ..."
[3]: https://www.reddit.com/r/OpenAI/comments/1c3b7e8/openais_whisper_filled_in_silent_part_at_the/?utm_source=chatgpt.com "OpenAI's Whisper filled in silent part at the beginning of ..."
[4]: https://arxiv.org/abs/2505.12969?utm_source=chatgpt.com "Calm-Whisper: Reduce Whisper Hallucination On Non-Speech By Calming Crazy Heads Down"
[5]: https://www.youtube.com/shorts/-8pujgUgiD4?utm_source=chatgpt.com "OpenAI Whisper's crazy hallucinations during long stretches of ..."
[6]: https://github.com/openai/whisper/discussions/679?utm_source=chatgpt.com "A possible solution to Whisper hallucination #679"
